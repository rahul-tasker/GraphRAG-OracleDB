# GraphRAG on Oracle 23ai
_convert documents to a knowledge graph for natural language questions using Oracle Database 23ai, Oracle GenAI Service and OpenAI's API

A Streamlit app that:
1) accepts a **.txt** or **.pdf** document,  
2) extracts entities & relationships with **LangChain’s `LLMGraphTransformer`**,  
3) uploads them to **Oracle Database 23ai (Autonomous Database Serverless)** as a SQL:2023 **Property Graph**, and  
4) lets you **ask natural-language questions**. The app uses **OCI Generative AI (Grok-3-fast)** to plan a SQL/PGQ query, executes it against Oracle DB, then sends the result rows to an LLM for a **natural-language answer**.  
There’s also an input to **append a sentence** and instantly create/merge new vertices/edges.

---

## Contents
- [Features](#features)
- [Architecture (high-level)](#architecture-high-level)
- [Prerequisites](#prerequisites)
- [Quick Start](#quick-start)
- [Configuration](#configuration)
- [Database Setup (DDL)](#database-setup-ddl)
- [How It Works in the UI](#how-it-works-in-the-ui)
- [Limits & Notes](#limits--notes)
- [Required OCI IAM Policies](#required-oci-iam-policies)
- [Troubleshooting](#troubleshooting)
- [FAQ](#faq)

---

## Features
- **One-file ingestion** (TXT/PDF) → **entity/relationship graph** (no chunking).
- **Oracle 23ai Property Graph**: stored in tables (`vertices`, `edges`) and exposed as `document_pg`.
- **LLM-planned queries**: OCI Generative AI (Grok-3-fast) writes SQL:2023 graph patterns (`GRAPH_TABLE(...) MATCH ...`).
- **Execution + Answering**: query runs in Oracle; results are summarized by an LLM to natural language.
- **Inline growth**: add a sentence to create **more vertices/edges** (with merge rules).

---

## Architecture (high-level)
- **Extraction**: LangChain **`LLMGraphTransformer`** turns raw text into nodes/edges.
- **Storage**: Upserts into `vertices`/`edges` (Autonomous Database Serverless; thin driver).
- **Query Planning**: OCI GenAI **Grok-3-fast** generates SQL/PGQ for Oracle Property Graph (`document_pg`).
- **Execution**: App runs the SQL against Oracle via `oracledb`.
- **Answering**: Result rows are fed to an LLM to produce a concise answer.

---

## Prerequisites
- **Python**: 3.11  
- **Conda** environment (recommended)
- **Oracle Autonomous Database Serverless** (23ai) with wallet
- **OpenAI API key** (used by LangChain’s `LLMGraphTransformer`)
- **OCI account** with access to **Generative AI Inference** (Grok-3-fast)

---

## Quick Start

### 1) Create & activate the env
```bash
conda create -n graphrag python=3.11 -y
conda activate graphrag
```

### 2) Install dependencies (pinned)
```bash
pip install -r requirements.txt
```

### 3) Configure credentials
Create a `.env` file at the repo root:

```ini
OPENAI_API_KEY=
ORA_USER=
ORA_PASS=
ORA_DSN=
TNS_ADMIN=
OCI_COMPARTMENT_OCID=
OCI_LLM_MODEL_OCID=
```

- `OPENAI_API_KEY`: used by LangChain for `LLMGraphTransformer`
- `ORA_*` + `TNS_ADMIN`: Oracle thin connection to ADB-S (wallet dir = `TNS_ADMIN`)
- `OCI_*`: OCIDs for compartment and the **Grok-3-fast** model endpoint you’ll call

> Your **OCI API keys / profile** should exist in `~/.oci/config` (profile: `DEFAULT` unless you change it in code).


### 4) Run the app
```bash
python -m streamlit run DataLoad.py
```

---

## Configuration
Most values are pulled from `.env`. In code:
- **Graph name**: `document_pg`  
- **Driver**: Oracle **thin** (no Instant Client needed)  
- **OCI Region**: `us-ashburn-1` (as configured in your OCI config)  
- **LLM for query planning**: **Grok-3-fast** via OCI Generative AI Inference  
- **LLM for final answer**: called via OCI (or as implemented in your code)  
- **Extraction LLM**: OpenAI (through LangChain)

---

## Database Setup (DDL)

> The following schema is created when a document is uploaded

```sql
-- 1) Tables
CREATE TABLE vertices (
  vid     VARCHAR2(400) PRIMARY KEY,
  vlabel  VARCHAR2(100) NOT NULL,
  props   JSON
);

CREATE TABLE edges (
  eid      NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
  src_vid  VARCHAR2(400) NOT NULL,
  dst_vid  VARCHAR2(400) NOT NULL,
  elabel   VARCHAR2(100) NOT NULL,
  props    JSON,
  CONSTRAINT fk_edges_src FOREIGN KEY (src_vid) REFERENCES vertices(vid),
  CONSTRAINT fk_edges_dst FOREIGN KEY (dst_vid) REFERENCES vertices(vid)
);

-- 2) Property Graph
CREATE PROPERTY GRAPH document_pg
  VERTEX TABLES (
    vertices KEY (vid)
      LABEL nodes
      PROPERTIES (vid, vlabel, props)
  )
  EDGE TABLES (
    edges KEY (eid)
      SOURCE KEY (src_vid) REFERENCES vertices(vid)
      DESTINATION KEY (dst_vid) REFERENCES vertices(vid)
      LABEL edges
      PROPERTIES (eid, src_vid, dst_vid, elabel, props)
  );
```

---

## How It Works in the UI
1. **Upload** a `.txt` or `.pdf` (single file).  
2. App invokes **`LLMGraphTransformer`** to extract entities (nodes) & relationships (edges).  
3. The pipeline **upserts** nodes/edges into Oracle (merging existing ones).  
4. Ask a **question** in plain English.  
5. OCI GenAI (**Grok-3-fast**) produces a **SQL:2023 graph pattern**; the app executes it with `oracledb`.  
6. The result rows are summarized to a **natural-language answer**.  
7. Use **“Add sentence”** to append new content and instantly create/merge nodes/edges.

**Merging behavior**  
By default, the pipeline merges into **existing vertices/edges** (exact-match logic in code), preventing duplicates where possible.

---

## Limits & Notes
- **Single file only** (no multi-file ingestion).  
- **No chunking** for extraction. The **effective max input size** is bounded by your extraction LLM’s **context window**.  
  - As a practical default, cap input to **~100k characters** (≈ a few dozen pages of clean text).  
  - PDFs must contain **digital text**; **scanned PDFs** require OCR (not included).  
- Property Graph name is fixed to **`document_pg`** (update in code if you change it).

---

## Required OCI IAM Policies
If you authenticate with a **user principal** (the account in `~/.oci/config`), ensure the **group** that user belongs to has permission to call Generative AI Inference in the right compartment.

Example (tenancy-level policy; replace bracketed values):

```
Allow group <YOUR_GROUP_NAME> to use generative-ai-family in compartment <YOUR_COMPARTMENT_NAME>
```

If you deploy on OCI and use **instance principals** or **functions**, create a **dynamic group** for that resource and grant the same permission to the dynamic group instead of a user group:

```
Allow dynamic-group <YOUR_DG_NAME> to use generative-ai-family in compartment <YOUR_COMPARTMENT_NAME>
```

> You may also need basic read on the model resource if it’s in another compartment. Keep policies scoped to the specific compartment you listed in `OCI_COMPARTMENT_OCID`.

---

## Troubleshooting
- **“I see a new relationship in SQL Developer but not in the app”**  
  - You likely forgot to `COMMIT` in SQL Developer. The app uses a **separate session** and won’t see uncommitted changes.  
  - Verify both tools connect to the **same DB/schema**. Run:
    ```sql
    SELECT sys_context('USERENV','SESSION_USER') AS user, ora_database_name AS db FROM dual;
    ```
- **Wallet / connection errors** (`DPI-` / `ORA-`):  
  - Confirm `TNS_ADMIN` points to your wallet directory and `ORA_DSN` matches a service in `tnsnames.ora`.  
- **OCI GenAI errors**:  
  - Check `OCI_COMPARTMENT_OCID` and `OCI_LLM_MODEL_OCID`.  
  - Confirm your **OCI profile** in `~/.oci/config` is `DEFAULT` (or update the code).  
  - Ensure your **IAM policy** includes `use generative-ai-family`.  
- **PDF text is empty**: the PDF might be **scanned**; add OCR pre-processing or convert to text first.  
- **Duplicate nodes/edges**: tune your merge logic (e.g., normalize `vid`, trim whitespace, case-fold).

---

## FAQ

**What file types are supported?**  
`.txt` and `.pdf`. Scanned PDFs aren’t supported unless you add OCR.

**Can I ingest multiple files?**  
Not in this version.

**Where is the graph stored?**  
In Oracle ADB-S tables (`vertices`, `edges`) surfaced as a Property Graph named `document_pg`.

**Which LLMs are used?**  
- **OpenAI API** (via LangChain) for the **`LLMGraphTransformer`** extraction.  
- **OCI Generative AI** (**Grok-3-fast**) for **query planning** (and final answer summarization if configured that way).

---

## Project Status & Author
- **Status**: Internal project / demo.  
- **Author**: Rahul Tasker | rahultasker@gmail.com
